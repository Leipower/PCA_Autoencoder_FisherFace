# -*- coding: utf-8 -*-
"""FisherFace.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S9-dpwgdKW0Q6jz4jDDdocf80qKrZnb5
"""

# Load the Drive helper and mount
from google.colab import drive

# This will prompt for authorization.
drive.mount('/content/drive')

# After executing the cell above, Drive
# files will be present in "/content/drive/My Drive".
!ls "/content/drive/My Drive/Colab Notebooks/data"

!pip install imageio

from google.colab import files
src = list(files.upload().values())[0]
open('mywarper.py','wb').write(src)

import numpy as np
import cv2
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.gridspec as gridspec
import sys
import datetime
import imageio
import skimage as skim
from skimage import color
import glob
import random
from sklearn.preprocessing import normalize
import scipy.io
from mywarper import warp
from scipy.linalg import eigh
import mywarper

random.seed(231)

"""**Several Functions Used**"""

def pca(sample):
    n,_ = sample.shape
    _, s, vh = np.linalg.svd(sample,full_matrices=False)
    principles = vh.T
    eigen_value = s**2/(n-1)
    return(principles,eigen_value)

def reconst_face(test_v_single,principles,n_pc,mean_train):
    test = test_v_single - mean_train
    test_v_weight = np.dot(test,principles)
    recon = mean_train + np.dot(test_v_weight[:n_pc],principles.T[:n_pc,:])
    errs = sum((recon-test_v_single)**2)
    return(recon,errs)

"""**Import the Data**"""

images_male = [mpimg.imread(file) for file in glob.glob('/content/drive/My Drive/Colab Notebooks/data/male_images/*.jpg')]
images_female = [mpimg.imread(file) for file in glob.glob('/content/drive/My Drive/Colab Notebooks/data/female_images/*.jpg')]
landmarks_male = [scipy.io.loadmat(file) for file in glob.glob('/content/drive/My Drive/Colab Notebooks/data/male_landmarks/*.mat')]
landmarks_female = [scipy.io.loadmat(file) for file in glob.glob('/content/drive/My Drive/Colab Notebooks/data/female_landmarks/*.mat')]

# Load the Original Dataset and Lable the Data; Male = 1, Female = -1
train_male = random.sample(range(412),330)
train_female = random.sample(range(588),470)
img_train_male = [skim.color.rgb2hsv(images_male[i]) for i in train_male]
img_test_male = [skim.color.rgb2hsv(images_male[i]) for i in range(412) if i not in train_male]
img_train_female = [skim.color.rgb2hsv(images_female[i]) for i in train_female]
img_test_female = [skim.color.rgb2hsv(images_female[i]) for i in range(588) if i not in train_female]

train_image = img_train_male+img_train_female
test_image = img_test_male+img_test_female

train_img_v = np.zeros((800,128*128))
test_img_v = np.zeros((200,128*128))

for i in range(800):
    v = train_image[i]
    train_img_v[i,:] = np.reshape(v[:,:,2],(1,-1))

for i in range(200):
    v = test_image[i]
    test_img_v[i,:] = np.reshape(v[:,:,2],(1,-1))

lm_list_male = []
for i in range(412):
    lm_list_male.append(np.array(list(landmarks_male[i].values()),dtype=object)[3])
lm_list_male = np.array(lm_list_male)
lm_list_female = []
for i in range(588):
    lm_list_female.append(np.array(list(landmarks_female[i].values()),dtype=object)[3])
lm_list_female = np.array(lm_list_female)
lm_train_male = [lm_list_male[i] for i in train_male]
lm_test_male = [lm_list_male[i] for i in range(412) if i not in train_male]
lm_train_female = [lm_list_female[i] for i in train_female]
lm_test_female = [lm_list_female[i] for i in range(588) if i not in train_female]

train_landmark = lm_train_male+lm_train_female
test_landmark = lm_test_male+lm_test_female

train_lm = np.zeros((800,68*2))
test_lm = np.zeros((200,68*2))

for i in range(800):
    v = train_landmark[i]
    train_lm[i,:] = np.reshape(v,(1,-1))

for i in range(200):
    v = test_landmark[i]
    test_lm[i,:] = np.reshape(v,(1,-1))

label_train = np.zeros(800,dtype=int)
label_test = np.zeros(200,dtype=int)
label_train[0:330]=label_train[0:330]+1
label_train[330:800]=label_train[330:800]-1
label_test[0:82]=label_test[0:82]+1
label_test[82:200]=label_test[82:200]-1

train_img_v.shape,test_img_v.shape,train_lm.shape,test_lm.shape

"""**Fisher Face Clasification with Geometry and Appearance together**"""

# PCA on Landmarks
mean_lm = train_lm.mean(axis=0)
train_lm = train_lm - mean_lm
principles_lm,e_value_lm = pca(train_lm)
trainlm_projection = np.dot(train_lm,principles_lm)[:,:10]
trainlm_projection.shape

# PCA on Images
for i in range(800):
  img = np.zeros([128,128,3])
  img[:,:,2] = np.reshape(train_img_v[i],(128,128))
  img = warp(img,np.reshape((train_lm+mean_lm)[i,:],(68,2)),mean_lm.reshape(68,2))
  train_img_v[i] = img[:,:,2].reshape(1,-1)

mean_img = train_img_v.mean(axis=0)
train_img_v = train_img_v-mean_img
principles_img,e_value_img = pca(train_img_v)
trainImg_projection = np.dot(train_img_v,principles_img)[:,:50]
trainlm_projection.shape,trainImg_projection.shape

## Fisher Face for Landmarks
mu_1 = trainlm_projection[:330,:].mean(axis=0)
mu_2 = trainlm_projection[330:800,:].mean(axis=0)
mu = trainlm_projection.mean(axis=0)

Sw = np.dot((trainlm_projection[:330,:]-mu_1).T,(trainlm_projection[:330,:]-mu_1))+np.dot((trainlm_projection[330:800,:]-mu_2).T,(trainlm_projection[330:800,:]-mu_2))
Sb = np.matmul((mu_1-mu).reshape((10,1)),(mu_1-mu).reshape((1,10)))+np.matmul((mu_2-mu).reshape((10,1)),(mu_2-mu).reshape((1,10)))
Sw.shape, Sb.shape
eigvals_lm, eigvecs_lm = eigh(Sb, Sw, eigvals_only=False)
recon_lm = mean_lm + np.dot(eigvecs_lm[:,eigvals_lm>0.00001].T,principles_lm.T[:10,:])

## Fisher Face for Appearance
mu_1 = trainImg_projection[:330,:].mean(axis=0)
mu_2 = trainImg_projection[330:800,:].mean(axis=0)
mu = trainImg_projection.mean(axis=0)

Sw = np.dot((trainImg_projection[:330,:]-mu_1).T,(trainImg_projection[:330,:]-mu_1))+np.dot((trainImg_projection[330:800,:]-mu_2).T,(trainImg_projection[330:800,:]-mu_2))
Sb = np.matmul((mu_1-mu).reshape((50,1)),(mu_1-mu).reshape((1,50)))+np.matmul((mu_2-mu).reshape((50,1)),(mu_2-mu).reshape((1,50)))
Sw.shape, Sb.shape
eigvals_img, eigvecs_img = eigh(Sb, Sw, eigvals_only=False)
recon_img = mean_img + np.dot(eigvecs_img[:,eigvals_img>0.00001].T,principles_img.T[:50,:])

#img = np.zeros([128,128,3])
#img[:,:,2] = np.reshape(recon_img,(128,128))
#img = warp(img,mean_lm.reshape(68,2),recon_lm.reshape(68,2))
#recon =  img[:,:,2].reshape(1,-1)
#plt.rcParams["axes.grid"] = False
#plt.imshow(recon.reshape(128,128),cmap='gray')
#plt.show()

# Project to the Fisher Features Space
c1 = []
c2 = []
for i in range(330):
  c1.append('red')
for i in range(470):
  c2.append('blue')
colors = c1+c2
Ds_lm = np.dot(trainlm_projection,eigvecs_lm[:,eigvals_lm>0.00001])
Ds_img = np.dot(trainImg_projection,eigvecs_img[:,eigvals_img>0.00001])
ax = plt.subplot()
ax.scatter(Ds_img[0:330],Ds_lm[0:330],color=colors[0:330],label='Male')
ax.scatter(Ds_img[330:800],Ds_lm[330:800],color=colors[330:800],label='Female')
plt.legend(loc='upper right', numpoints=1, ncol=3, fontsize=8, bbox_to_anchor=(0, 0))
plt.show()

"""**Fisher Face Clasification with Appearance only**"""

# PCA on Images
mean_img = train_img_v.mean(axis=0)
train_img_v = train_img_v-mean_img
principles_img,e_value_img = pca(train_img_v)
trainImg_projection = np.dot(train_img_v,principles_img)[:,:50]
testImg_projection = np.dot((test_img_v-mean_img),principles_img)[:,:50]

## Fisher Face for Appearance
mu_1 = trainImg_projection[:330,:].mean(axis=0)
mu_2 = trainImg_projection[330:800,:].mean(axis=0)
mu = trainImg_projection.mean(axis=0)

Sw = np.dot((trainImg_projection[:330,:]-mu_1).T,(trainImg_projection[:330,:]-mu_1))+np.dot((trainImg_projection[330:800,:]-mu_2).T,(trainImg_projection[330:800,:]-mu_2))
Sb = np.matmul((mu_1-mu).reshape((50,1)),(mu_1-mu).reshape((1,50)))+np.matmul((mu_2-mu).reshape((50,1)),(mu_2-mu).reshape((1,50)))
Sw.shape, Sb.shape
eigvals, eigvecs = eigh(Sb, Sw, eigvals_only=False)
recon_img = mean_img + np.dot(eigvecs[:,eigvals>0.00001].T,principles_img.T[:50,:])

plt.rcParams["axes.grid"] = False
plt.imshow(recon_img.reshape(128,128),cmap='gray')
plt.show()

# Discriminant Scores
Ds = np.dot(testImg_projection,eigvecs[:,eigvals>0.00001])

"""**Classification Error**"""

Prediction_Accuracy = sum(Ds.reshape(200)*(-label_test)>0)/200
Prediction_Accuracy